# @Higress 挑战赛 智能路由方向架构参考与评分标准

**当前现状与挑战**

随着大模型应用的深入，企业和服务商通常会部署一个由多种模型组成的“模型矩阵”，而非依赖单一的通用大模型。这个矩阵可能包含一个或多个能力顶尖但成本高昂的旗舰模型（如qwen3-max），以及多个经过微调、在特定领域（如代码生成、财报分析）表现出色且成本效益更高的垂直小模型。然而，当前API网关大多采用简单的、与内容无关的路由策略（如基于URL路径），无法理解AI请求的内在语义。这种“语义盲”的路由方式导致所有请求，无论简单或复杂，都被发往同一个默认模型，造成了严重的资源错配：简单任务使用昂贵模型导致成本浪费，而复杂任务被发往能力不足的模型则导致效果不佳。

‍

**赛题目标**

本赛题要求参赛者为Higress设计并实现一个具备​**语义感知（Semantic-Aware）能力的智能路由插件**。该插件的核心目标是成为一个LLM流量的智能调度器，它能实时解析符合OpenAI协议的API请求，深刻理解其内在的任务意图、复杂度和所需工具，然后将请求动态、精准地转发至预定义模型池中最合适的模型。此外，插件需依托网关的流量拦截能力，实现一个“数据飞轮”机制：从真实的API交互中自动生成标注数据，用于持续迭代和优化路由模型本身。

‍

**技术要求与架构参考**

参赛者需要设计并训练一个轻量级的“智能路由模型”，并将其集成到Higress插件中，设计方案可以参考以下内容（不限于）：

​ **(1)路由模型核心**​：插件的核心是一个能对输入请求进行快速分类或评估的预测模型。该模型接收用户Prompt作为输入，输出目标模型的标识符。参赛者可以探索多种实现路径：  
a. ​**分类器方法**​：训练一个高效的文本分类器（例如，基于DistilBERT或更轻量的模型），将不同的用户意图（如“闲聊”、“代码生成”、“摘要提取”）映射到不同的后端模型服务。  
b. ​**语义匹配方法**：为每个后端模型定义一组“典型查询”的Embedding向量。插件在运行时计算新请求的Embedding，并通过向量相似度计算（如余弦相似度）来决定最佳路由目标。

​ **(2)自优化数据流水线**​：插件需要实现一个可配置的“数据生成模式”。在此模式下，插件可以将请求同时发往“路由模型选择的经济型模型”和一个“基准旗舰模型”，并将`{request, model\_A\_output, model\_B\_output, latency, cost}`等信息记录下来，形成高质量的训练/评估数据集，为路由模型的持续迭代提供数据基础。

 **(3)性能与可控性**：路由决策过程必须在毫秒级完成，以避免对端到端延迟产生显著影响。同时，整个系统必须提供清晰、易于操作的**权衡（Trade-off）机制**，允许运维人员通过简单配置（如调整一个置信度阈值）在“成本优先”和“质量优先”两种策略间灵活切换。

‍

**赛题评审标准**

本赛题的评审将综合评估路由策略的智能化程度、对系统性能（成本、延迟、准确率）的实际优化效果，以及整体架构的创新性和工程质量。

**方案架构设计 (30分)**

- 路由策略与理论支撑 (15)：路由模型的设计是否合理、高效，并有清晰的理论依据。对路由策略（如分类、语义匹配等）的选择论证是否充分。数据飞轮和自优化机制的设计是否具备可行性和创新性。
- 方案完整性 (10)：设计是否全面考虑了多模型管理、动态配置等实际问题。所提供的成本/质量权衡机制是否设计良好、易于操作。

- 先进性与创新性 (5)：是否在语义路由、数据生成或模型迭代方面提出了新颖且有效的实现方法。

**方案代码实现 (50分)**

- 核心路由逻辑实现 (25)：完整、高效地实现语义感知的路由转发逻辑。插件能够正确解析请求并根据路由模型的决策结果将流量导向不同的后端LLM。
- 可复现的效果验证 (25)：提供一套完整的基准测试方案和脚本。在给定的测试集上，量化评估插件在**答案准确率**、**访问延时**和**综合成本**三个维度上的表现，并证明其相比简单的轮询策略有显著的综合收益。  
  **测试集及验证集访问地址：https://github.com/alibaba/higress/issues/2946**

**非功能性指标 (20分)**

- 代码质量与文档 (10)：代码风格清晰，注释充分，文档详尽，包含架构图、设计决策和用户指南。
- 性能与稳定性 (10)：路由插件本身引入的延迟极低。在并发请求下，系统运行稳定，资源消耗合理。

‍
