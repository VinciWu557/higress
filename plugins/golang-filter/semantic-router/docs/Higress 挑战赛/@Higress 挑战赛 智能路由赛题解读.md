# @Higress 挑战赛 智能路由赛题解读

**目标：智能、高效、数据驱动的 LLM 路由**

在现实世界的 LLM 应用中，并非所有请求都具有同等的复杂性。用一个庞大、昂贵的模型来回答简单问题是资源的浪费；而用一个小模型处理复杂任务则无法保证效果。本赛题的使命是构建一个智能路由系统，它能够根据请求内容的语义，将其精准地分发给最合适的模型，从而在成本、延迟和准确性之间找到最佳平衡。

‍

**架构灵感：vLLM Semantic Router**

本赛题的概念模型源自社区的优秀开源项目 [@vLLM semantic-router](@vLLM%20semantic-router.md)。

其核心工作机制是：

- **语义分类：使用一个轻量级的分类模型（例如 BERT），对传入请求的语义**进行分析，并将其意图分类（例如，“这是一个编码问题”、“这是一个数学问题”等）。
- **Envoy 集成：该项目通过 Envoy 的**  `ext_proc` 扩展机制实现，这与为 Higress（同样基于 Envoy）构建插件的思路形成了直接的平行参考。

‍

**核心创新：自优化的数据流水线**

这是本赛题最关键、最具创新性的要求。需要实现的不仅仅是一个静态的路由器，而是一个能够持续自我进化的系统。

具体要求是：网关在处理请求时，除了将请求路由到**预测的最佳模型**（例如模型 A），还必须**同时**将该请求发送给一个**基线模型**（例如模型 B）。

- 数据收集：插件必须为每个请求捕获一条完整的、结构化的数据记录，格式为 {request, model_A_output, model_B_output, latency, cost}。这些高质量的、带有并行结果的数据，将成为未来迭代训练的宝贵财富。
- 飞轮效应：这个设计创造了一个强大的“飞轮效应”。初始的路由模型进行预测；系统通过并行调用收集到更精准的训练数据；使用这些新数据可以训练出更好的路由模型；更优的模型做出更精准的预测，从而收集到质量更高的数据……如此循环，系统便进入了一个持续自我优化的正向循环。这体现了 MLOps 和系统设计的核心思想，是衡量方案先进性的关键。

‍

**评估与测试：使用官方 Mock 服务**

本赛题提供了一套完整的 Mock 服务和评估 API，所有开发和测试都必须基于此进行。需要严格遵循此处定义的规范：

[https://github.com/alibaba/higress/issues/2946](https://github.com/alibaba/higress/issues/2946)

**开发与验证流程：**

1. **数据收集阶段：**

- 使用训练数据集服务 `http://sem-router-train.higress.io/questions` 获取问题列表。
- 对于每个问题，插件应将其**并行发送**给多个模型（例如，一个通用大模型和一个或多个领域专用小模型）。

2. **获取真值分数：**

- 对于每个模型返回的答案，**必须**调用 `/v1/evaluate` 接口来获取一个客观的正确性分数。这个分数将作为训练数据的标签（label）。

3. **训练分类器：**

- 使用收集到的数据（包含问题文本、使用的模型、延迟、成本以及评估分数），训练一个分类模型。这个模型的任务是：输入一个问题，输出预测的最佳模型。

4. **部署与验证阶段：**

- 使用验证数据集服务 `http://sem-router-verify.higress.io/questions` 获取验证问题。

  此时，插件应使用上一步训练好的分类器，为每个问题选择**唯一一个**模型进行调用。

5. **客观评估：**

- 作品的客观得分，将基于在**整个验证集**上的平均准确率（来自 `/v1/evaluate` 接口）和平均响应延迟。
