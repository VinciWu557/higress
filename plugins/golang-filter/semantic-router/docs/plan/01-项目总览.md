# Higress 智能语义路由插件 - 项目总览

## 项目背景

本项目旨在为 Higress 开发一个**语义感知的智能路由插件**，参加 Higress 挑战赛智能路由方向。该插件能够根据用户问题内容自动选择最适合的 LLM 模型，在保证回答准确性的同时优化响应延时和成本。

## 核心目标

1. **智能路由**: 根据问题语义自动选择最优模型 (数学/代码/医学/写作等专业模型)
2. **数据飞轮**: 实现自动化的训练数据收集与模型迭代机制
3. **高性能**: 路由决策延迟控制在 50ms 以内
4. **高准确率**: 在验证集上实现高准确率和低延迟的平衡

## 技术架构

### 系统架构图

```
┌─────────────┐
│   Client    │
└──────┬──────┘
       │ HTTP POST /v1/chat/completions
       ↓
┌─────────────────────────────────────────┐
│         Higress Gateway                 │
│  ┌───────────────────────────────────┐  │
│  │  Semantic Router Plugin (Golang)  │  │
│  │  ┌─────────────────────────────┐  │  │
│  │  │  1. 解析用户问题            │  │  │
│  │  │  2. 语义分类 (gRPC调用)     │  │  │
│  │  │  3. 模型选择                │  │  │
│  │  │  4. 设置路由头              │  │  │
│  │  │  5. 数据收集 (可选)         │  │  │
│  │  └─────────────────────────────┘  │  │
│  └───────────────────────────────────┘  │
└──────┬──────────────────────────────────┘
       │ 根据 X-Target-Model 路由
       ↓
┌─────────────────────────────────────────┐
│        模型后端服务池                   │
│  ┌──────────┐  ┌──────────┐           │
│  │qwen-math │  │qwen-code │  ...      │
│  └──────────┘  └──────────┘           │
└─────────────────────────────────────────┘
       │
       ↓
┌─────────────────────────────────────────┐
│    分类服务 (gRPC)                      │
│  ┌─────────────────────────────────┐   │
│  │  ModernBERT 分类模型            │   │
│  │  - Category Classifier (10类)   │   │
│  │  - PII Detector (可选)          │   │
│  │  - Jailbreak Guard (可选)       │   │
│  └─────────────────────────────────┘   │
└─────────────────────────────────────────┘
```

## 核心组件

### 1. Higress Golang Filter Plugin
- **语言**: Go
- **职责**:
  - 拦截 HTTP 请求
  - 提取用户问题
  - 调用分类服务
  - 执行路由决策
  - 收集训练数据

### 2. 分类服务 (gRPC)
- **语言**: Go + Python (模型推理)
- **职责**:
  - 接收用户问题
  - 执行语义分类
  - 返回类别 + 置信度
  - 支持批量推理优化

### 3. 模型训练管线
- **语言**: Python
- **职责**:
  - 数据预处理
  - 模型训练 (ModernBERT + LoRA)
  - 模型评估
  - 配置生成

### 4. 数据收集与评估服务
- **语言**: Go/Python
- **职责**:
  - 接收路由决策数据
  - 调用 `/v1/evaluate` 评分
  - 生成训练数据集
  - 性能监控

## 参考架构: vLLM Semantic Router

本项目借鉴 vLLM Semantic Router 的以下核心设计:

| 组件 | vLLM Semantic Router | Higress 实现 | 适配说明 |
|------|---------------------|--------------|----------|
| **网关** | Envoy Proxy + ExtProc | Higress (基于 Envoy) | 使用 Golang Filter 替代 ExtProc |
| **分类模型** | ModernBERT (3任务) | ModernBERT (Category分类) | 复用架构,简化为核心任务 |
| **路由决策** | 基于 category + confidence | 基于 category + score | 相同 |
| **缓存机制** | 语义缓存 (可选) | 简单缓存 (可选) | 简化实现 |
| **数据收集** | 无 | **数据飞轮机制** | 核心创新 |
| **评分机制** | 无 | `/v1/evaluate` API | 比赛要求 |

## 技术选型

### 模型选择: ModernBERT Base

**选择理由**:
- ✅ 延迟低 (~20ms vs GPT 200-500ms)
- ✅ 成本低 ($0.0001 vs $0.002-0.03 per query)
- ✅ 确定性输出 (一致性高)
- ✅ 支持本地部署 (无需外部 API)
- ✅ 可使用 LoRA 微调 (参数效率提升 99%+)

**性能对比**:
| 指标 | BERT-base | ModernBERT-base | 提升 |
|------|-----------|----------------|------|
| 准确率 | 89.2% | 92.7% | +3.5% |
| 推理速度 | 100ms | 85ms | +15% |
| 显存占用 | 400MB | 380MB | +5% |

### 微调策略: LoRA

**优势**:
- 可训练参数: 0.2% (~300K vs 149M)
- 显存占用: 0.8GB (vs 2.4GB, 减少 67%)
- 训练时间: 减少 50%
- 模型体积: 2-10MB (vs 149MB+, 减少 98%)
- 训练成本: $5-20 (vs $50-200, 减少 80-90%)

### 数据集选择

| 任务 | 数据集 | 规模 | 用途 |
|------|--------|------|------|
| **类别分类** | MMLU-Pro | ~10,000 | 训练 10 类语义分类器 |
| **验证评估** | Mock 服务验证集 | 比赛提供 | 最终评分 |
| **训练数据** | Mock 服务训练集 | 比赛提供 | 数据收集与优化 |

## 评分标准 (总分 100)

### 方案架构设计 (30分)
- **路由策略与理论支撑 (15分)**
  - ModernBERT 分类器设计
  - 数据飞轮机制设计
  - 模型选择策略

- **方案完整性 (10分)**
  - 多模型管理
  - 动态配置
  - 成本/质量权衡机制

- **先进性与创新性 (5分)**
  - LoRA 微调优化
  - 自动化训练数据生成
  - 性能优化措施

### 方案代码实现 (50分)
- **核心路由逻辑实现 (25分)**
  - Higress Golang Filter
  - gRPC 分类服务
  - 路由决策引擎

- **可复现的效果验证 (25分)**
  - 准确率评估
  - 延迟测试
  - 成本分析

### 非功能性指标 (20分)
- **代码质量与文档 (10分)**
  - 代码规范
  - 注释充分
  - 架构文档
  - 用户指南

- **性能与稳定性 (10分)**
  - 路由延迟 < 50ms
  - 并发性能
  - 错误处理

## 成功指标

### 核心指标

1. **准确率**:
   - 目标: 验证集平均准确率 > 85%
   - 测量: `/v1/evaluate` API 评分

2. **响应延迟**:
   - 目标: 端到端延迟 < 基线延迟 + 50ms
   - 测量: 请求总耗时

3. **资源效率**:
   - 小模型使用率 > 60%
   - 成本降低 > 40%

### 技术指标

| 组件 | 性能目标 |
|------|---------|
| 分类推理 | < 30ms (p99) |
| gRPC 通信 | < 10ms |
| 路由决策 | < 5ms |
| 缓存命中率 | > 20% (可选) |

## 风险与挑战

### 技术风险

1. **分类准确率不足**
   - 缓解: 使用 LoRA 微调 + MMLU-Pro 训练
   - 备选: 增加训练数据量

2. **延迟过高**
   - 缓解: 批量推理 + 连接池优化
   - 备选: 模型量化 (ONNX/TensorRT)

3. **数据收集复杂**
   - 缓解: 异步上报 + 采样策略
   - 备选: 简化数据格式

### 资源风险

1. **GPU 资源不足**
   - 缓解: 使用 CPU 训练 (LoRA 支持)
   - 备选: 使用预训练模型

2. **时间限制**
   - 缓解: 优先实现核心功能
   - 备选: 分阶段提交

## 下一步行动

参见详细实施计划:
- [阶段一: 基础框架搭建](./02-阶段一-基础框架.md)
- [阶段二: 分类服务开发](./03-阶段二-分类服务.md)
- [阶段三: 模型训练](./04-阶段三-模型训练.md)
- [阶段四: 数据飞轮](./05-阶段四-数据飞轮.md)
- [阶段五: 测试与优化](./06-阶段五-测试优化.md)
