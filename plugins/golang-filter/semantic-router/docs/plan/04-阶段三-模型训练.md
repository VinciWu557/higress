# 阶段三: 模型训练

## 目标

训练 ModernBERT 语义分类模型，使用 LoRA 微调优化参数效率。

**预期成果**:
- ✅ 完成 MMLU-Pro 数据集的分类器训练
- ✅ 模型在验证集上准确率 > 90%
- ✅ 推理延迟 < 30ms
- ✅ 导出可部署的模型文件

**预计时间**: 3-4 天

---

## 任务清单

### Task 3.1: 训练环境搭建

**目标**: 搭建模型训练环境

**项目结构**:
```
training/
├── requirements.txt
├── dataset/                      # 数据集目录
│   ├── download.py               # 数据集下载脚本
│   └── preprocess.py             # 数据预处理
├── models/                       # 训练脚本
│   ├── train_category.py         # 类别分类训练
│   ├── train_lora.py             # LoRA 微调
│   └── export.py                 # 模型导出
├── configs/                      # 训练配置
│   ├── category_config.yaml
│   └── lora_config.yaml
├── evaluation/                   # 评估脚本
│   ├── evaluate.py
│   └── analyze_results.py
└── outputs/                      # 训练输出
    ├── checkpoints/
    ├── logs/
    └── final_models/
```

**依赖** (`requirements.txt`):
```txt
torch==2.1.0
transformers==4.36.0
datasets==2.15.0
peft==0.7.0                        # LoRA
accelerate==0.25.0
scikit-learn==1.3.2
pandas==2.1.4
matplotlib==3.8.2
tensorboard==2.15.1
tqdm==4.66.1
```

**安装**:
```bash
cd training
pip install -r requirements.txt
```

**验收标准**:
- ✅ 所有依赖安装成功
- ✅ 可以导入相关库
- ✅ GPU 可用 (可选)

---

### Task 3.2: MMLU-Pro 数据集准备

**目标**: 下载并预处理 MMLU-Pro 数据集

**下载脚本** (`dataset/download.py`):
```python
from datasets import load_dataset
import json
import os

def download_mmlu_pro():
    """下载 MMLU-Pro 数据集"""
    print("Downloading MMLU-Pro dataset...")

    # 从 HuggingFace 加载数据集
    dataset = load_dataset("TIGER-Lab/MMLU-Pro")

    # 保存到本地
    output_dir = "./data/mmlu_pro"
    os.makedirs(output_dir, exist_ok=True)

    # 保存训练集和验证集
    dataset['train'].to_json(f"{output_dir}/train.jsonl")
    dataset['validation'].to_json(f"{output_dir}/validation.jsonl")
    dataset['test'].to_json(f"{output_dir}/test.jsonl")

    print(f"Dataset saved to {output_dir}")
    print(f"Train: {len(dataset['train'])} examples")
    print(f"Validation: {len(dataset['validation'])} examples")
    print(f"Test: {len(dataset['test'])} examples")

    return dataset

if __name__ == '__main__':
    download_mmlu_pro()
```

**预处理脚本** (`dataset/preprocess.py`):
```python
import json
import pandas as pd
from collections import Counter

# 类别映射 (MMLU-Pro → 我们的10类)
CATEGORY_MAPPING = {
    "mathematics": "math",
    "computer science": "code",
    "physics": "physics",
    "chemistry": "chemistry",
    "biology": "biology",
    "engineering": "engineering",
    "law": "law",
    "medicine": "medicine",
    "other": "general",
}

# 我们的目标类别
TARGET_CATEGORIES = [
    "math",
    "code",
    "medicine",
    "writing",
    "physics",
    "chemistry",
    "biology",
    "engineering",
    "law",
    "general"
]

def preprocess_mmlu_pro(input_file, output_file, max_samples_per_category=1000):
    """
    预处理 MMLU-Pro 数据集

    格式转换:
    {
        "question": "...",
        "category": "mathematics",
        "options": ["A", "B", "C", "D"],
        "answer": "A"
    }
    →
    {
        "text": "question text",
        "label": "math"
    }
    """
    print(f"Processing {input_file}...")

    with open(input_file, 'r') as f:
        data = [json.loads(line) for line in f]

    processed = []
    category_counts = Counter()

    for item in data:
        # 提取问题文本
        text = item['question']

        # 映射类别
        raw_category = item.get('category', 'other').lower()
        label = CATEGORY_MAPPING.get(raw_category, 'general')

        # 类别平衡: 限制每个类别的样本数
        if category_counts[label] >= max_samples_per_category:
            continue

        processed.append({
            "text": text,
            "label": label
        })

        category_counts[label] += 1

    # 保存处理后的数据
    with open(output_file, 'w') as f:
        for item in processed:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')

    print(f"Processed {len(processed)} examples")
    print("Category distribution:")
    for cat, count in category_counts.most_common():
        print(f"  {cat}: {count}")

    return processed

def create_label_mapping():
    """创建标签映射"""
    label2id = {label: idx for idx, label in enumerate(TARGET_CATEGORIES)}
    id2label = {idx: label for label, idx in label2id.items()}

    mapping = {
        "label2id": label2id,
        "id2label": id2label,
        "num_labels": len(TARGET_CATEGORIES)
    }

    with open("./data/label_mapping.json", 'w') as f:
        json.dump(mapping, f, indent=2)

    print("Label mapping created:")
    print(json.dumps(mapping, indent=2))

    return mapping

if __name__ == '__main__':
    # 预处理训练集
    preprocess_mmlu_pro(
        "./data/mmlu_pro/train.jsonl",
        "./data/processed/train.jsonl",
        max_samples_per_category=1000
    )

    # 预处理验证集
    preprocess_mmlu_pro(
        "./data/mmlu_pro/validation.jsonl",
        "./data/processed/validation.jsonl",
        max_samples_per_category=200
    )

    # 创建标签映射
    create_label_mapping()
```

**验收标准**:
- ✅ MMLU-Pro 数据集下载成功
- ✅ 数据预处理完成
- ✅ 类别分布均衡

---

### Task 3.3: LoRA 微调训练

**目标**: 使用 LoRA 微调 ModernBERT

**训练配置** (`configs/lora_config.yaml`):
```yaml
# 模型配置
model:
  base_model: "answerdotai/ModernBERT-base"
  task_type: "sequence_classification"
  num_labels: 10

# LoRA 配置
lora:
  rank: 8                          # 低秩矩阵维度
  alpha: 16                        # 缩放因子
  dropout: 0.1
  target_modules:                  # 应用 LoRA 的模块
    - "query"
    - "value"
    - "key"
    - "dense"

# 训练配置
training:
  output_dir: "./outputs/lora_category_classifier"
  num_epochs: 3
  batch_size: 8
  learning_rate: 1e-4
  weight_decay: 0.01
  warmup_ratio: 0.06

  # 评估策略
  eval_strategy: "steps"
  eval_steps: 100
  save_steps: 200

  # 早停
  early_stopping_patience: 2

  # 性能优化
  fp16: true                       # 混合精度训练
  gradient_checkpointing: true

# 数据配置
data:
  train_file: "./data/processed/train.jsonl"
  validation_file: "./data/processed/validation.jsonl"
  max_length: 512
```

**训练脚本** (`models/train_lora.py`):
```python
import os
import json
import yaml
import torch
from datasets import load_dataset
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TrainingArguments,
    Trainer,
    DataCollatorWithPadding,
    EarlyStoppingCallback
)
from peft import (
    get_peft_model,
    LoraConfig,
    TaskType,
    PeftModel
)
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score
import numpy as np

def load_config(config_path):
    """加载配置文件"""
    with open(config_path, 'r') as f:
        return yaml.safe_load(f)

def load_label_mapping(mapping_path):
    """加载标签映射"""
    with open(mapping_path, 'r') as f:
        return json.load(f)

def prepare_dataset(data_file, tokenizer, max_length, label2id):
    """准备数据集"""
    # 加载数据
    dataset = load_dataset('json', data_files=data_file, split='train')

    # 分词函数
    def tokenize_function(examples):
        # 分词
        tokenized = tokenizer(
            examples['text'],
            padding=False,
            truncation=True,
            max_length=max_length
        )

        # 添加标签
        tokenized['labels'] = [label2id[label] for label in examples['label']]

        return tokenized

    # 应用分词
    tokenized_dataset = dataset.map(
        tokenize_function,
        batched=True,
        remove_columns=dataset.column_names
    )

    return tokenized_dataset

def compute_metrics(eval_pred):
    """计算评估指标"""
    predictions, labels = eval_pred
    predictions = np.argmax(predictions, axis=1)

    return {
        'accuracy': accuracy_score(labels, predictions),
        'f1': f1_score(labels, predictions, average='weighted'),
        'precision': precision_score(labels, predictions, average='weighted'),
        'recall': recall_score(labels, predictions, average='weighted')
    }

def train_lora_classifier(config_path):
    """训练 LoRA 分类器"""
    # 加载配置
    config = load_config(config_path)
    label_mapping = load_label_mapping("./data/label_mapping.json")

    print("=" * 80)
    print("Training Configuration")
    print("=" * 80)
    print(yaml.dump(config, default_flow_style=False))

    # 加载分词器
    print("Loading tokenizer...")
    tokenizer = AutoTokenizer.from_pretrained(config['model']['base_model'])

    # 准备数据集
    print("Preparing datasets...")
    train_dataset = prepare_dataset(
        config['data']['train_file'],
        tokenizer,
        config['data']['max_length'],
        label_mapping['label2id']
    )

    eval_dataset = prepare_dataset(
        config['data']['validation_file'],
        tokenizer,
        config['data']['max_length'],
        label_mapping['label2id']
    )

    print(f"Train size: {len(train_dataset)}")
    print(f"Eval size: {len(eval_dataset)}")

    # 加载基础模型
    print("Loading base model...")
    model = AutoModelForSequenceClassification.from_pretrained(
        config['model']['base_model'],
        num_labels=config['model']['num_labels'],
        id2label=label_mapping['id2label'],
        label2id=label_mapping['label2id']
    )

    # 配置 LoRA
    print("Configuring LoRA...")
    lora_config = LoraConfig(
        task_type=TaskType.SEQ_CLS,
        r=config['lora']['rank'],
        lora_alpha=config['lora']['alpha'],
        lora_dropout=config['lora']['dropout'],
        target_modules=config['lora']['target_modules'],
        bias="none"
    )

    # 应用 LoRA
    model = get_peft_model(model, lora_config)
    model.print_trainable_parameters()

    # 训练参数
    training_args = TrainingArguments(
        output_dir=config['training']['output_dir'],
        num_train_epochs=config['training']['num_epochs'],
        per_device_train_batch_size=config['training']['batch_size'],
        per_device_eval_batch_size=config['training']['batch_size'],
        learning_rate=config['training']['learning_rate'],
        weight_decay=config['training']['weight_decay'],
        warmup_ratio=config['training']['warmup_ratio'],

        evaluation_strategy=config['training']['eval_strategy'],
        eval_steps=config['training']['eval_steps'],
        save_strategy="steps",
        save_steps=config['training']['save_steps'],

        load_best_model_at_end=True,
        metric_for_best_model="f1",
        greater_is_better=True,

        fp16=config['training']['fp16'],
        gradient_checkpointing=config['training']['gradient_checkpointing'],

        logging_dir=f"{config['training']['output_dir']}/logs",
        logging_steps=50,
        report_to="tensorboard"
    )

    # 数据整理器
    data_collator = DataCollatorWithPadding(tokenizer)

    # 创建 Trainer
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=eval_dataset,
        tokenizer=tokenizer,
        data_collator=data_collator,
        compute_metrics=compute_metrics,
        callbacks=[
            EarlyStoppingCallback(
                early_stopping_patience=config['training']['early_stopping_patience']
            )
        ]
    )

    # 开始训练
    print("=" * 80)
    print("Starting training...")
    print("=" * 80)
    trainer.train()

    # 评估最终模型
    print("=" * 80)
    print("Final evaluation...")
    print("=" * 80)
    eval_results = trainer.evaluate()
    print(json.dumps(eval_results, indent=2))

    # 保存模型
    print("Saving model...")
    output_path = f"{config['training']['output_dir']}/final_model"
    trainer.save_model(output_path)
    tokenizer.save_pretrained(output_path)

    # 保存标签映射
    with open(f"{output_path}/label_mapping.json", 'w') as f:
        json.dump(label_mapping, f, indent=2)

    print(f"Model saved to {output_path}")

    return trainer, eval_results

if __name__ == '__main__':
    train_lora_classifier("./configs/lora_config.yaml")
```

**启动训练**:
```bash
cd training
python models/train_lora.py
```

**验收标准**:
- ✅ 训练成功完成
- ✅ 验证集准确率 > 90%
- ✅ F1 分数 > 0.88
- ✅ 模型文件正确保存

---

### Task 3.4: 模型评估

**目标**: 全面评估模型性能

**评估脚本** (`evaluation/evaluate.py`):
```python
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from peft import PeftModel
from datasets import load_dataset
from sklearn.metrics import classification_report, confusion_matrix
import json
import time
import numpy as np

def load_model(model_path):
    """加载训练好的模型"""
    print(f"Loading model from {model_path}...")

    tokenizer = AutoTokenizer.from_pretrained(model_path)

    # 加载模型 (LoRA)
    model = AutoModelForSequenceClassification.from_pretrained(model_path)
    model.eval()

    # 加载标签映射
    with open(f"{model_path}/label_mapping.json", 'r') as f:
        label_mapping = json.load(f)

    return tokenizer, model, label_mapping

def evaluate_model(model_path, test_file):
    """评估模型"""
    # 加载模型
    tokenizer, model, label_mapping = load_model(model_path)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)

    # 加载测试数据
    test_dataset = load_dataset('json', data_files=test_file, split='train')

    # 评估
    predictions = []
    labels = []
    latencies = []

    print(f"Evaluating on {len(test_dataset)} examples...")

    for example in test_dataset:
        text = example['text']
        true_label = example['label']

        # 分词
        inputs = tokenizer(
            text,
            return_tensors="pt",
            padding=True,
            truncation=True,
            max_length=512
        ).to(device)

        # 推理
        start_time = time.time()
        with torch.no_grad():
            outputs = model(**inputs)
            logits = outputs.logits
            probs = torch.softmax(logits, dim=-1)

        latency = (time.time() - start_time) * 1000
        latencies.append(latency)

        # 预测
        pred_idx = probs.argmax().item()
        pred_label = label_mapping['id2label'][str(pred_idx)]

        predictions.append(pred_label)
        labels.append(true_label)

    # 计算指标
    print("=" * 80)
    print("Classification Report")
    print("=" * 80)
    print(classification_report(labels, predictions))

    # 混淆矩阵
    print("=" * 80)
    print("Confusion Matrix")
    print("=" * 80)
    cm = confusion_matrix(labels, predictions)
    print(cm)

    # 性能统计
    print("=" * 80)
    print("Performance Statistics")
    print("=" * 80)
    print(f"Average latency: {np.mean(latencies):.2f}ms")
    print(f"P50 latency: {np.percentile(latencies, 50):.2f}ms")
    print(f"P95 latency: {np.percentile(latencies, 95):.2f}ms")
    print(f"P99 latency: {np.percentile(latencies, 99):.2f}ms")

    return {
        "predictions": predictions,
        "labels": labels,
        "latencies": latencies
    }

if __name__ == '__main__':
    evaluate_model(
        "./outputs/lora_category_classifier/final_model",
        "./data/processed/validation.jsonl"
    )
```

**验收标准**:
- ✅ 准确率 > 90%
- ✅ 平均延迟 < 30ms
- ✅ P99 延迟 < 50ms

---

### Task 3.5: 模型导出与部署

**目标**: 导出模型用于生产部署

**导出脚本** (`models/export.py`):
```python
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from peft import PeftModel
import json
import shutil
import os

def export_for_deployment(model_path, output_path):
    """
    导出模型用于部署

    合并 LoRA 权重到基础模型
    """
    print(f"Exporting model from {model_path}...")

    # 创建输出目录
    os.makedirs(output_path, exist_ok=True)

    # 加载模型
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForSequenceClassification.from_pretrained(model_path)

    # 保存合并后的模型
    print("Saving merged model...")
    model.save_pretrained(output_path)
    tokenizer.save_pretrained(output_path)

    # 复制标签映射
    shutil.copy(
        f"{model_path}/label_mapping.json",
        f"{output_path}/label_mapping.json"
    )

    # 保存模型配置
    config = {
        "model_type": "modernbert-lora",
        "task": "sequence_classification",
        "num_labels": model.config.num_labels,
        "max_length": 512,
        "device": "cpu"  # 部署时的默认设备
    }

    with open(f"{output_path}/deployment_config.json", 'w') as f:
        json.dump(config, f, indent=2)

    print(f"Model exported to {output_path}")

    # 测试导出的模型
    print("Testing exported model...")
    test_model(output_path)

def test_model(model_path):
    """测试导出的模型"""
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForSequenceClassification.from_pretrained(model_path)
    model.eval()

    with open(f"{model_path}/label_mapping.json", 'r') as f:
        label_mapping = json.load(f)

    # 测试用例
    test_cases = [
        "求解方程 x^2 + 2x - 3 = 0",
        "写一个 Python 快速排序算法",
        "头痛的常见原因有哪些?"
    ]

    for text in test_cases:
        inputs = tokenizer(text, return_tensors="pt", padding=True, truncation=True)

        with torch.no_grad():
            outputs = model(**inputs)
            probs = torch.softmax(outputs.logits, dim=-1)

        pred_idx = probs.argmax().item()
        pred_label = label_mapping['id2label'][str(pred_idx)]
        confidence = probs[0][pred_idx].item()

        print(f"Text: {text}")
        print(f"Prediction: {pred_label} (confidence: {confidence:.3f})")
        print("-" * 80)

if __name__ == '__main__':
    export_for_deployment(
        "./outputs/lora_category_classifier/final_model",
        "./outputs/deployed_model"
    )
```

**部署包结构**:
```
deployed_model/
├── config.json                    # 模型配置
├── pytorch_model.bin              # 模型权重
├── vocab.txt                      # 词表
├── tokenizer_config.json          # 分词器配置
├── label_mapping.json             # 标签映射
└── deployment_config.json         # 部署配置
```

**验收标准**:
- ✅ 模型导出成功
- ✅ 导出的模型可正常加载
- ✅ 推理结果正确

---

## 性能优化

### Optimization 3.1: 批量推理

**目标**: 支持批量推理以提升吞吐量

在 `classifier.py` 中已实现 `classify_batch` 方法,确保在 gRPC 服务中启用。

### Optimization 3.2: 模型量化 (可选)

**INT8 量化**:
```python
from torch.quantization import quantize_dynamic

# 动态量化
quantized_model = quantize_dynamic(
    model,
    {torch.nn.Linear},
    dtype=torch.qint8
)

# 保存量化模型
torch.save(quantized_model.state_dict(), "quantized_model.pth")
```

---

## 里程碑验收

### 验收清单

- [ ] **数据准备**
  - [ ] MMLU-Pro 数据集下载完成
  - [ ] 数据预处理完成
  - [ ] 类别分布均衡

- [ ] **模型训练**
  - [ ] LoRA 微调成功
  - [ ] 训练收敛
  - [ ] 验证集性能达标

- [ ] **模型评估**
  - [ ] 准确率 > 90%
  - [ ] F1 > 0.88
  - [ ] 延迟 < 30ms

- [ ] **模型部署**
  - [ ] 模型导出成功
  - [ ] 可集成到分类服务

### 交付物

1. **训练脚本**: `training/models/train_lora.py`
2. **评估报告**: `training/evaluation/report.md`
3. **导出模型**: `training/outputs/deployed_model/`
4. **训练日志**: `training/outputs/logs/`

---

## 下一步

完成阶段三后,进入 [阶段四: 数据飞轮](./05-阶段四-数据飞轮.md)
