# 阶段四: 数据飞轮机制

## 目标

实现自动化的训练数据收集与模型迭代机制,这是本项目的核心创新点。

**预期成果**:
- ✅ 实现数据收集模式 (并行调用多个模型)
- ✅ 集成 `/v1/evaluate` 评分接口
- ✅ 自动生成训练数据集
- ✅ 支持模型迭代优化

**预计时间**: 4-5 天

---

## 核心概念: 数据飞轮

### 什么是数据飞轮?

数据飞轮是一个自优化的闭环系统:

```
┌─────────────────────────────────────────────────┐
│                 数据飞轮循环                     │
│                                                 │
│  ┌─────────┐    ┌─────────┐    ┌─────────┐    │
│  │ 1. 收集 │ -> │ 2. 评分 │ -> │ 3. 训练 │    │
│  │  数据   │    │  标注   │    │  模型   │    │
│  └────┬────┘    └─────────┘    └────┬────┘    │
│       │                              │         │
│       │         ┌─────────┐          │         │
│       └────────>│ 4. 部署 │<─────────┘         │
│                 │  优化   │                    │
│                 └─────────┘                    │
└─────────────────────────────────────────────────┘
```

### 工作流程

1. **数据收集阶段**:
   - 用户发送问题到 Higress
   - 插件识别为"训练模式"
   - 并行调用所有候选模型
   - 收集所有模型的答案

2. **评分阶段**:
   - 对每个模型的答案调用 `/v1/evaluate`
   - 获取准确性评分 (0-1)
   - 记录 `{question, model, answer, score}` 映射

3. **数据存储**:
   - 将评分数据存储到数据库/文件
   - 定期聚合生成新的训练集

4. **模型优化**:
   - 基于新数据重新训练分类器
   - 更新路由策略
   - 部署新模型

---

## 任务清单

### Task 4.1: 数据收集模式设计

**目标**: 在插件中实现数据收集模式

**配置更新** (`config.go`):
```go
// DataCollectionConfig 数据收集配置
type DataCollectionConfig struct {
    Enabled         bool
    Mode            string  // "training" | "production"
    SamplingRate    float64 // 采样率 (0.0-1.0)
    StorageEndpoint string  // 数据存储服务地址

    // 训练模式特有配置
    Training TrainingModeConfig
}

// TrainingModeConfig 训练模式配置
type TrainingModeConfig struct {
    // 并行调用的模型列表
    CandidateModels []string

    // 评分服务配置
    EvaluateEndpoint string
    EvaluateTimeout  int

    // 批量上报配置
    BatchSize      int
    FlushInterval  int // 秒
}
```

**配置示例**:
```yaml
data_collection:
  enabled: true
  mode: "training"              # training | production
  sampling_rate: 1.0            # 训练模式下采样100%
  storage_endpoint: "http://data-collector:8080/collect"

  training:
    # 候选模型列表
    candidate_models:
      - "qwen-max"
      - "qwen-math-7b"
      - "qwen-code-7b"
      - "qwen-medicine-7b"
      - "qwen-writing-7b"

    # 评分服务
    evaluate_endpoint: "http://sem-router-train.higress.io/v1/evaluate"
    evaluate_timeout: 5000      # ms

    # 批量上报
    batch_size: 10
    flush_interval: 60
```

**验收标准**:
- ✅ 配置结构完整
- ✅ 支持训练/生产模式切换
- ✅ 参数验证完善

---

### Task 4.2: 并行模型调用实现

**目标**: 实现并行调用多个模型并收集结果

**数据结构** (`client/types.go`):
```go
package client

// ModelResponse 单个模型的响应
type ModelResponse struct {
    Model      string                 // 模型名称
    Answer     string                 // 模型答案
    Latency    int64                  // 响应延迟 (ms)
    Error      error                  // 错误信息
    RawResponse map[string]interface{} // 原始响应
}

// TrainingDataPoint 训练数据点
type TrainingDataPoint struct {
    Question      string                    // 用户问题
    Responses     map[string]*ModelResponse // model -> response
    Scores        map[string]float64        // model -> score
    Timestamp     int64                     // 时间戳
    Classification *ClassificationResult    // 分类结果
}
```

**并行调用实现** (`client/parallel.go`):
```go
package client

import (
    "context"
    "encoding/json"
    "fmt"
    "io"
    "net/http"
    "strings"
    "sync"
    "time"
)

// ParallelCaller 并行模型调用器
type ParallelCaller struct {
    httpClient *http.Client
    baseURL    string
}

// NewParallelCaller 创建并行调用器
func NewParallelCaller(baseURL string, timeout time.Duration) *ParallelCaller {
    return &ParallelCaller{
        httpClient: &http.Client{
            Timeout: timeout,
        },
        baseURL: baseURL,
    }
}

// CallModels 并行调用多个模型
func (pc *ParallelCaller) CallModels(
    ctx context.Context,
    question string,
    models []string,
) map[string]*ModelResponse {

    var wg sync.WaitGroup
    results := make(map[string]*ModelResponse)
    var mu sync.Mutex

    // 为每个模型启动一个 goroutine
    for _, model := range models {
        wg.Add(1)

        go func(modelName string) {
            defer wg.Done()

            // 调用单个模型
            response := pc.callSingleModel(ctx, question, modelName)

            // 保存结果
            mu.Lock()
            results[modelName] = response
            mu.Unlock()
        }(model)
    }

    // 等待所有调用完成
    wg.Wait()

    return results
}

// callSingleModel 调用单个模型
func (pc *ParallelCaller) callSingleModel(
    ctx context.Context,
    question string,
    model string,
) *ModelResponse {

    startTime := time.Now()

    // 构造请求体
    requestBody := map[string]interface{}{
        "model": model,
        "messages": []map[string]string{
            {"role": "user", "content": question},
        },
        "stream": false,
    }

    bodyBytes, _ := json.Marshal(requestBody)

    // 创建请求
    req, err := http.NewRequestWithContext(
        ctx,
        "POST",
        fmt.Sprintf("%s/v1/chat/completions", pc.baseURL),
        strings.NewReader(string(bodyBytes)),
    )
    if err != nil {
        return &ModelResponse{
            Model: model,
            Error: err,
        }
    }

    req.Header.Set("Content-Type", "application/json")

    // 发送请求
    resp, err := pc.httpClient.Do(req)
    if err != nil {
        return &ModelResponse{
            Model:   model,
            Error:   err,
            Latency: time.Since(startTime).Milliseconds(),
        }
    }
    defer resp.Body.Close()

    // 读取响应
    bodyBytes, err = io.ReadAll(resp.Body)
    if err != nil {
        return &ModelResponse{
            Model:   model,
            Error:   err,
            Latency: time.Since(startTime).Milliseconds(),
        }
    }

    // 解析响应
    var rawResponse map[string]interface{}
    if err := json.Unmarshal(bodyBytes, &rawResponse); err != nil {
        return &ModelResponse{
            Model:       model,
            Error:       err,
            Latency:     time.Since(startTime).Milliseconds(),
            RawResponse: rawResponse,
        }
    }

    // 提取答案
    answer := extractAnswer(rawResponse)

    return &ModelResponse{
        Model:       model,
        Answer:      answer,
        Latency:     time.Since(startTime).Milliseconds(),
        RawResponse: rawResponse,
    }
}

// extractAnswer 从响应中提取答案
func extractAnswer(rawResponse map[string]interface{}) string {
    choices, ok := rawResponse["choices"].([]interface{})
    if !ok || len(choices) == 0 {
        return ""
    }

    choice, ok := choices[0].(map[string]interface{})
    if !ok {
        return ""
    }

    message, ok := choice["message"].(map[string]interface{})
    if !ok {
        return ""
    }

    content, ok := message["content"].(string)
    if !ok {
        return ""
    }

    return content
}
```

**验收标准**:
- ✅ 并行调用逻辑正确
- ✅ 错误处理完善
- ✅ 超时控制有效
- ✅ 并发安全

---

### Task 4.3: 评分接口集成

**目标**: 集成 `/v1/evaluate` 接口对答案评分

**评分客户端** (`client/evaluator.go`):
```go
package client

import (
    "bytes"
    "context"
    "encoding/json"
    "fmt"
    "io"
    "net/http"
    "time"
)

// EvaluateRequest 评分请求
type EvaluateRequest struct {
    Question string `json:"question"`
    Answer   string `json:"answer"`
}

// EvaluateResponse 评分响应
type EvaluateResponse struct {
    Score float64 `json:"score"` // 0-1, -1表示无效
}

// Evaluator 评分客户端
type Evaluator struct {
    httpClient *http.Client
    endpoint   string
}

// NewEvaluator 创建评分客户端
func NewEvaluator(endpoint string, timeout time.Duration) *Evaluator {
    return &Evaluator{
        httpClient: &http.Client{
            Timeout: timeout,
        },
        endpoint: endpoint,
    }
}

// Evaluate 评估答案
func (e *Evaluator) Evaluate(ctx context.Context, question, answer string) (float64, error) {
    // 构造请求
    reqBody := EvaluateRequest{
        Question: question,
        Answer:   answer,
    }

    bodyBytes, err := json.Marshal(reqBody)
    if err != nil {
        return -1, fmt.Errorf("marshal request failed: %w", err)
    }

    req, err := http.NewRequestWithContext(
        ctx,
        "POST",
        e.endpoint,
        bytes.NewReader(bodyBytes),
    )
    if err != nil {
        return -1, fmt.Errorf("create request failed: %w", err)
    }

    req.Header.Set("Content-Type", "application/json")

    // 发送请求
    resp, err := e.httpClient.Do(req)
    if err != nil {
        return -1, fmt.Errorf("request failed: %w", err)
    }
    defer resp.Body.Close()

    if resp.StatusCode != http.StatusOK {
        return -1, fmt.Errorf("evaluate failed with status: %d", resp.StatusCode)
    }

    // 解析响应
    respBody, err := io.ReadAll(resp.Body)
    if err != nil {
        return -1, fmt.Errorf("read response failed: %w", err)
    }

    var evalResp EvaluateResponse
    if err := json.Unmarshal(respBody, &evalResp); err != nil {
        return -1, fmt.Errorf("unmarshal response failed: %w", err)
    }

    return evalResp.Score, nil
}

// EvaluateMultiple 批量评估多个答案
func (e *Evaluator) EvaluateMultiple(
    ctx context.Context,
    question string,
    responses map[string]*ModelResponse,
) map[string]float64 {

    scores := make(map[string]float64)

    for model, resp := range responses {
        if resp.Error != nil || resp.Answer == "" {
            scores[model] = -1.0
            continue
        }

        score, err := e.Evaluate(ctx, question, resp.Answer)
        if err != nil {
            scores[model] = -1.0
        } else {
            scores[model] = score
        }
    }

    return scores
}
```

**验收标准**:
- ✅ 评分接口调用成功
- ✅ 响应解析正确
- ✅ 支持批量评估

---

### Task 4.4: 数据收集流程集成

**目标**: 在 filter 中集成完整的数据收集流程

**更新 filter.go**:
```go
package semantic_router

import (
    "context"
    "encoding/json"
    "fmt"
    "time"

    "github.com/alibaba/higress/plugins/golang-filter/semantic-router/client"
    "github.com/envoyproxy/envoy/contrib/golang/common/go/api"
)

// filter 添加数据收集相关字段
type filter struct {
    api.PassThroughStreamFilter

    callbacks  api.FilterCallbackHandler
    config     PluginConfig

    bodyBuf    []byte
    needBody   bool
    reqHeaders api.RequestHeaderMap

    // 运行时组件
    grpc       *client.GRPCClassifierClient
    cache      *cache.Manager
    engine     *rengine.Engine

    // 数据收集组件
    parallelCaller *client.ParallelCaller
    evaluator      *client.Evaluator
    collector      *DataCollector
}

// newFilter 更新构造函数
func newFilter(cfg PluginConfig, cb api.FilterCallbackHandler) api.StreamFilter {
    f := &filter{
        callbacks: cb,
        config:    cfg,
    }

    // ... 原有初始化 ...

    // 初始化数据收集组件
    if cfg.DataCollection.Enabled {
        f.parallelCaller = client.NewParallelCaller(
            cfg.DataCollection.Training.EvaluateEndpoint, // 使用相同的 base URL
            time.Duration(cfg.DataCollection.Training.EvaluateTimeout)*time.Millisecond,
        )

        f.evaluator = client.NewEvaluator(
            cfg.DataCollection.Training.EvaluateEndpoint,
            time.Duration(cfg.DataCollection.Training.EvaluateTimeout)*time.Millisecond,
        )

        f.collector = NewDataCollector(
            cfg.DataCollection.StorageEndpoint,
            cfg.DataCollection.Training.BatchSize,
            cfg.DataCollection.Training.FlushInterval,
        )
    }

    return f
}

// DecodeData 更新以支持数据收集模式
func (f *filter) DecodeData(buffer api.BufferInstance, endStream bool) api.StatusType {
    if !f.needBody {
        return api.Continue
    }

    f.bodyBuf = append(f.bodyBuf, buffer.Bytes()...)
    if !endStream {
        return api.StopAndBuffer
    }

    // 提取 prompt
    prompt := prpt.ExtractPromptFromOpenAIBody(f.bodyBuf)
    if prompt == "" {
        return api.Continue
    }

    // 检查是否为训练模式
    if f.config.DataCollection.Enabled && f.config.DataCollection.Mode == "training" {
        // 训练模式: 收集数据
        go f.collectTrainingData(prompt)

        // 仍然执行正常路由 (使用分类器)
        f.handleNormalRouting(prompt)
    } else {
        // 生产模式: 正常路由
        f.handleNormalRouting(prompt)
    }

    f.needBody = false
    return api.Continue
}

// handleNormalRouting 正常路由逻辑
func (f *filter) handleNormalRouting(prompt string) {
    // 缓存检查
    cacheKey := fmt.Sprintf("sr:%s", hashText(prompt))
    if v, ok := f.cache.Get(cacheKey); ok {
        if res, ok2 := v.(*client.ClassificationResult); ok2 {
            f.applyRouting(res)
            return
        }
    }

    // 调用分类服务
    ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
    defer cancel()

    res, err := f.grpc.Classify(ctx, prompt, f.config.Cache.Enabled)
    if err != nil {
        api.LogWarnf("semantic-router: classify failed: %v", err)
        f.setHeaders("general", 0.5, f.config.Routing.DefaultModel, "fallback")
        return
    }

    f.cache.Set(cacheKey, res)
    f.applyRouting(res)
}

// collectTrainingData 收集训练数据 (异步)
func (f *filter) collectTrainingData(question string) {
    ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
    defer cancel()

    // 1. 并行调用所有候选模型
    responses := f.parallelCaller.CallModels(
        ctx,
        question,
        f.config.DataCollection.Training.CandidateModels,
    )

    // 2. 评估所有答案
    scores := f.evaluator.EvaluateMultiple(ctx, question, responses)

    // 3. 构造训练数据点
    dataPoint := &client.TrainingDataPoint{
        Question:  question,
        Responses: responses,
        Scores:    scores,
        Timestamp: time.Now().Unix(),
    }

    // 4. 发送到数据收集器
    if err := f.collector.Collect(dataPoint); err != nil {
        api.LogWarnf("semantic-router: collect data failed: %v", err)
    }

    // 5. 日志记录
    api.LogInfof("semantic-router: collected training data for question (scores: %v)", scores)
}
```

**验收标准**:
- ✅ 训练模式可正常触发
- ✅ 并行调用所有模型
- ✅ 评分结果正确
- ✅ 数据收集不阻塞主请求

---

### Task 4.5: 数据收集器实现

**目标**: 实现批量数据上报机制

**数据收集器** (`collector.go`):
```go
package semantic_router

import (
    "bytes"
    "encoding/json"
    "fmt"
    "net/http"
    "sync"
    "time"

    "github.com/alibaba/higress/plugins/golang-filter/semantic-router/client"
    "github.com/envoyproxy/envoy/contrib/golang/common/go/api"
)

// DataCollector 数据收集器
type DataCollector struct {
    endpoint      string
    batchSize     int
    flushInterval time.Duration

    mu            sync.Mutex
    buffer        []*client.TrainingDataPoint
    httpClient    *http.Client

    stopCh        chan struct{}
}

// NewDataCollector 创建数据收集器
func NewDataCollector(endpoint string, batchSize int, flushIntervalSec int) *DataCollector {
    dc := &DataCollector{
        endpoint:      endpoint,
        batchSize:     batchSize,
        flushInterval: time.Duration(flushIntervalSec) * time.Second,
        buffer:        make([]*client.TrainingDataPoint, 0, batchSize),
        httpClient:    &http.Client{Timeout: 10 * time.Second},
        stopCh:        make(chan struct{}),
    }

    // 启动定时刷新
    go dc.startPeriodicFlush()

    return dc
}

// Collect 收集一个数据点
func (dc *DataCollector) Collect(dataPoint *client.TrainingDataPoint) error {
    dc.mu.Lock()
    defer dc.mu.Unlock()

    // 添加到缓冲区
    dc.buffer = append(dc.buffer, dataPoint)

    // 如果达到批量大小,立即刷新
    if len(dc.buffer) >= dc.batchSize {
        return dc.flushLocked()
    }

    return nil
}

// startPeriodicFlush 启动定时刷新
func (dc *DataCollector) startPeriodicFlush() {
    ticker := time.NewTicker(dc.flushInterval)
    defer ticker.Stop()

    for {
        select {
        case <-ticker.C:
            dc.mu.Lock()
            if len(dc.buffer) > 0 {
                _ = dc.flushLocked()
            }
            dc.mu.Unlock()

        case <-dc.stopCh:
            return
        }
    }
}

// flushLocked 刷新缓冲区 (需持有锁)
func (dc *DataCollector) flushLocked() error {
    if len(dc.buffer) == 0 {
        return nil
    }

    // 准备上报数据
    batch := make([]*client.TrainingDataPoint, len(dc.buffer))
    copy(batch, dc.buffer)

    // 清空缓冲区
    dc.buffer = dc.buffer[:0]

    // 异步上报
    go dc.uploadBatch(batch)

    return nil
}

// uploadBatch 上报批量数据
func (dc *DataCollector) uploadBatch(batch []*client.TrainingDataPoint) {
    // 构造请求体
    payload := map[string]interface{}{
        "data_points": batch,
        "count":       len(batch),
        "timestamp":   time.Now().Unix(),
    }

    bodyBytes, err := json.Marshal(payload)
    if err != nil {
        api.LogErrorf("semantic-router: marshal batch failed: %v", err)
        return
    }

    // 发送 HTTP 请求
    req, err := http.NewRequest(
        "POST",
        dc.endpoint,
        bytes.NewReader(bodyBytes),
    )
    if err != nil {
        api.LogErrorf("semantic-router: create request failed: %v", err)
        return
    }

    req.Header.Set("Content-Type", "application/json")

    resp, err := dc.httpClient.Do(req)
    if err != nil {
        api.LogErrorf("semantic-router: upload batch failed: %v", err)
        return
    }
    defer resp.Body.Close()

    if resp.StatusCode != http.StatusOK {
        api.LogWarnf("semantic-router: upload batch failed with status: %d", resp.StatusCode)
        return
    }

    api.LogInfof("semantic-router: uploaded %d data points successfully", len(batch))
}

// Stop 停止数据收集器
func (dc *DataCollector) Stop() {
    close(dc.stopCh)

    // 刷新剩余数据
    dc.mu.Lock()
    _ = dc.flushLocked()
    dc.mu.Unlock()
}
```

**验收标准**:
- ✅ 批量上报机制正常
- ✅ 定时刷新工作
- ✅ 并发安全

---

### Task 4.6: 数据存储服务

**目标**: 实现简单的数据存储服务接收训练数据

**存储服务** (`data-collector-service/main.go`):
```go
package main

import (
    "encoding/json"
    "fmt"
    "log"
    "net/http"
    "os"
    "sync"
    "time"
)

// TrainingDataPoint 训练数据点
type TrainingDataPoint struct {
    Question   string                 `json:"question"`
    Responses  map[string]interface{} `json:"responses"`
    Scores     map[string]float64     `json:"scores"`
    Timestamp  int64                  `json:"timestamp"`
}

// CollectRequest 收集请求
type CollectRequest struct {
    DataPoints []*TrainingDataPoint `json:"data_points"`
    Count      int                  `json:"count"`
    Timestamp  int64                `json:"timestamp"`
}

// DataStore 数据存储
type DataStore struct {
    mu       sync.Mutex
    filePath string
    file     *os.File
}

// NewDataStore 创建数据存储
func NewDataStore(filePath string) (*DataStore, error) {
    file, err := os.OpenFile(filePath, os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644)
    if err != nil {
        return nil, err
    }

    return &DataStore{
        filePath: filePath,
        file:     file,
    }, nil
}

// Save 保存数据点
func (ds *DataStore) Save(dataPoints []*TrainingDataPoint) error {
    ds.mu.Lock()
    defer ds.mu.Unlock()

    for _, dp := range dataPoints {
        // 转为 JSONL 格式
        line, err := json.Marshal(dp)
        if err != nil {
            return err
        }

        // 写入文件
        if _, err := ds.file.Write(append(line, '\n')); err != nil {
            return err
        }
    }

    // 刷新到磁盘
    return ds.file.Sync()
}

// Close 关闭存储
func (ds *DataStore) Close() error {
    return ds.file.Close()
}

// handleCollect 处理收集请求
func handleCollect(store *DataStore) http.HandlerFunc {
    return func(w http.ResponseWriter, r *http.Request) {
        if r.Method != http.MethodPost {
            http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
            return
        }

        // 解析请求
        var req CollectRequest
        if err := json.NewDecoder(r.Body).Decode(&req); err != nil {
            http.Error(w, fmt.Sprintf("Invalid request: %v", err), http.StatusBadRequest)
            return
        }

        // 保存数据
        if err := store.Save(req.DataPoints); err != nil {
            log.Printf("Failed to save data: %v", err)
            http.Error(w, "Internal server error", http.StatusInternalServerError)
            return
        }

        log.Printf("Received %d data points", req.Count)

        // 返回成功
        w.Header().Set("Content-Type", "application/json")
        json.NewEncoder(w).Encode(map[string]interface{}{
            "status":  "success",
            "count":   req.Count,
            "message": "Data collected successfully",
        })
    }
}

func main() {
    // 创建数据存储
    dataDir := "./data"
    os.MkdirAll(dataDir, 0755)

    fileName := fmt.Sprintf("%s/training_data_%s.jsonl", dataDir, time.Now().Format("20060102"))
    store, err := NewDataStore(fileName)
    if err != nil {
        log.Fatalf("Failed to create data store: %v", err)
    }
    defer store.Close()

    // 设置路由
    http.HandleFunc("/collect", handleCollect(store))

    // 健康检查
    http.HandleFunc("/health", func(w http.ResponseWriter, r *http.Request) {
        w.WriteHeader(http.StatusOK)
        w.Write([]byte("OK"))
    })

    // 启动服务
    port := 8080
    log.Printf("Data collector service started on port %d", port)
    log.Printf("Saving data to %s", fileName)

    if err := http.ListenAndServe(fmt.Sprintf(":%d", port), nil); err != nil {
        log.Fatalf("Server failed: %v", err)
    }
}
```

**Dockerfile**:
```dockerfile
FROM golang:1.21-alpine

WORKDIR /app

COPY . .

RUN go build -o data-collector main.go

EXPOSE 8080

CMD ["./data-collector"]
```

**验收标准**:
- ✅ 服务可接收数据
- ✅ 数据保存为 JSONL 格式
- ✅ 按日期分文件存储

---

### Task 4.7: 训练数据生成脚本

**目标**: 从收集的数据生成模型训练所需格式

**数据转换脚本** (`scripts/generate_training_data.py`):
```python
import json
import argparse
from collections import Counter, defaultdict

def load_collected_data(file_path):
    """加载收集的数据"""
    data_points = []
    with open(file_path, 'r') as f:
        for line in f:
            data_points.append(json.loads(line))
    return data_points

def select_best_model_per_question(data_points):
    """
    为每个问题选择得分最高的模型作为标签

    输出格式:
    {
        "text": "question",
        "label": "best_model_category"
    }
    """
    training_examples = []

    # 模型到类别的映射
    model_to_category = {
        "qwen-max": "general",
        "qwen-math-7b": "math",
        "qwen-code-7b": "code",
        "qwen-medicine-7b": "medicine",
        "qwen-writing-7b": "writing",
    }

    for dp in data_points:
        question = dp['question']
        scores = dp['scores']

        # 找到得分最高的模型
        best_model = max(scores.items(), key=lambda x: x[1])
        model_name = best_model[0]
        score = best_model[1]

        # 过滤低分样本
        if score < 0.5:
            continue

        # 映射到类别
        category = model_to_category.get(model_name, "general")

        training_examples.append({
            "text": question,
            "label": category,
            "score": score,
            "best_model": model_name
        })

    return training_examples

def analyze_data_quality(training_examples):
    """分析数据质量"""
    print("=" * 80)
    print("Data Quality Analysis")
    print("=" * 80)

    # 类别分布
    label_counts = Counter([ex['label'] for ex in training_examples])
    print("\nLabel Distribution:")
    for label, count in label_counts.most_common():
        print(f"  {label}: {count}")

    # 得分统计
    scores = [ex['score'] for ex in training_examples]
    print(f"\nScore Statistics:")
    print(f"  Mean: {sum(scores) / len(scores):.3f}")
    print(f"  Min: {min(scores):.3f}")
    print(f"  Max: {max(scores):.3f}")

    # 每个类别的平均得分
    category_scores = defaultdict(list)
    for ex in training_examples:
        category_scores[ex['label']].append(ex['score'])

    print(f"\nAverage Score by Category:")
    for category, scores in category_scores.items():
        avg = sum(scores) / len(scores)
        print(f"  {category}: {avg:.3f}")

def save_training_data(training_examples, output_file):
    """保存训练数据"""
    with open(output_file, 'w') as f:
        for ex in training_examples:
            # 只保留训练需要的字段
            f.write(json.dumps({
                "text": ex['text'],
                "label": ex['label']
            }, ensure_ascii=False) + '\n')

    print(f"\nSaved {len(training_examples)} training examples to {output_file}")

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--input', required=True, help='Input collected data file')
    parser.add_argument('--output', required=True, help='Output training data file')
    parser.add_argument('--min-score', type=float, default=0.5, help='Minimum score threshold')
    args = parser.parse_args()

    # 加载数据
    print(f"Loading data from {args.input}...")
    data_points = load_collected_data(args.input)
    print(f"Loaded {len(data_points)} data points")

    # 生成训练样本
    print("\nGenerating training examples...")
    training_examples = select_best_model_per_question(data_points)

    # 分析数据质量
    analyze_data_quality(training_examples)

    # 保存训练数据
    save_training_data(training_examples, args.output)

if __name__ == '__main__':
    main()
```

**使用示例**:
```bash
python scripts/generate_training_data.py \
  --input ./data/training_data_20250110.jsonl \
  --output ./data/processed/new_training.jsonl \
  --min-score 0.6
```

**验收标准**:
- ✅ 数据转换正确
- ✅ 类别标签准确
- ✅ 数据质量分析清晰

---

## 测试与验证

### Test 4.1: 数据收集端到端测试

**测试脚本** (`test/test_data_collection.sh`):
```bash
#!/bin/bash

echo "Testing data collection mode..."

# 1. 启动数据收集服务
echo "Starting data collector service..."
cd data-collector-service
go run main.go &
COLLECTOR_PID=$!
sleep 2

# 2. 配置 Higress 为训练模式
# (假设已配置)

# 3. 发送测试问题
echo "Sending test questions..."
curl -X POST http://localhost:8001/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [{"role": "user", "content": "求解方程 x^2 + 2x - 3 = 0"}]
  }'

sleep 5

# 4. 检查数据文件
echo "Checking collected data..."
if [ -f "./data/training_data_*.jsonl" ]; then
    echo "✓ Data collection successful"
    cat ./data/training_data_*.jsonl | head -n 1 | jq .
else
    echo "✗ Data collection failed"
    exit 1
fi

# 清理
kill $COLLECTOR_PID

echo "Test completed!"
```

---

## 里程碑验收

### 验收清单

- [ ] **数据收集模式**
  - [ ] 配置正确解析
  - [ ] 并行调用所有模型
  - [ ] 评分接口集成成功
  - [ ] 数据上报正常

- [ ] **数据存储**
  - [ ] 存储服务可接收数据
  - [ ] 数据格式正确
  - [ ] 批量上报工作

- [ ] **数据转换**
  - [ ] 训练数据生成脚本正常
  - [ ] 数据质量分析清晰
  - [ ] 可用于模型训练

### 交付物

1. **数据收集代码**: `filter.go`, `client/parallel.go`, `client/evaluator.go`
2. **数据收集器**: `collector.go`
3. **存储服务**: `data-collector-service/`
4. **数据转换脚本**: `scripts/generate_training_data.py`
5. **测试脚本**: `test/test_data_collection.sh`

---

## 下一步

完成阶段四后,进入 [阶段五: 测试与优化](./06-阶段五-测试优化.md)
